{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criteo 1 TiB benchmark\n",
    "\n",
    "In this experiment we will evalutate a number of machine learning tools on a varying size of train data to determine how fast they learn, how much memory they consume etc.\n",
    "在这个实验中，我们将在不同大小的训练数据上评估许多机器学习工具，以确定它们学习的速度、消耗的内存等。\n",
    "\n",
    "We will assess Vowpal Wabbit and XGBoost in local mode, and Spark.ML models in cluster mode.\n",
    "\n",
    "我们将在本地模式下评估Vowpal Wabbit和XGBoost，在集群模式下评估Spark.ML模型。\n",
    "\n",
    "We will use terabyte click logs released by Criteo and sample needed amount of data from them.\n",
    "\n",
    "我们将使用Criteo发布的TB点击日志，并从中获取所需的数据量。\n",
    "\n",
    "\n",
    "This instance of experiment notebook focuses on data preparation and training VW & XGBoost locally.\n",
    "本实验笔记本集中于数据准备和本地 training VW & XGBoost。\n",
    "\n",
    "Let's go!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh /data/dataset/fengwen/script/criteo-1tb-benchmark/resume.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh /data/dataset/fengwen/script/make.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "* [Configuration](#Configuration)\n",
    "* [Data preparation](#Data-preparation)\n",
    "  * [Criteo → LibSVM](#Criteo-→-LibSVM)\n",
    "  * [LibSVM → Train and test (sampling)](#LibSVM-→-Train-and-test-(sampling%29)\n",
    "  * [LibSVM train and test → VW train and test](#LibSVM-train-and-test-→-VW-train-and-test)\n",
    "  * [Local data](#Local-data)\n",
    "* [Local training](#Local-training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 323 ms (started: 2022-11-16 12:54:39 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# encoding：utf-8\n",
    "%load_ext autotime\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "[_(back to toc)_](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.14 ms (started: 2022-11-16 12:54:40 +00:00)\n"
     ]
    }
   ],
   "source": [
    "criteo_data_remote_path = 'criteo/plain'\n",
    "libsvm_data_remote_path = 'criteo/libsvm'\n",
    "vw_data_remote_path = 'criteo/vw'\n",
    "\n",
    "local_data_path = 'criteo/data'\n",
    "local_results_path = 'criteo/results'\n",
    "local_runtime_path = 'criteo/runtime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.29 ms (started: 2022-11-16 12:54:40 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "criteo_day_template = os.path.join(criteo_data_remote_path, 'day{}')\n",
    "libsvm_day_template = os.path.join(libsvm_data_remote_path, 'day{}')\n",
    "vw_day_template = os.path.join(vw_data_remote_path, 'day{}')\n",
    "\n",
    "libsvm_train_template = os.path.join(libsvm_data_remote_path, 'train', '{}')\n",
    "libsvm_test_template = os.path.join(libsvm_data_remote_path, 'test', '{}')\n",
    "vw_train_template = os.path.join(vw_data_remote_path, 'train', '{}')\n",
    "vw_test_template = os.path.join(vw_data_remote_path, 'test', '{}')\n",
    "\n",
    "local_libsvm_test_template = os.path.join(local_data_path, 'data.test.{}.libsvm')\n",
    "local_libsvm_train_template = os.path.join(local_data_path, 'data.train.{}.libsvm')\n",
    "local_vw_test_template = os.path.join(local_data_path, 'data.test.{}.vw')\n",
    "local_vw_train_template = os.path.join(local_data_path, 'data.train.{}.vw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 295 µs (started: 2022-11-16 12:54:40 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def ensure_directory_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.61 ms (started: 2022-11-16 12:54:40 +00:00)\n"
     ]
    }
   ],
   "source": [
    "file_lists = [libsvm_data_remote_path, criteo_data_remote_path, vw_data_remote_path, local_data_path, local_results_path, local_runtime_path]\n",
    "\n",
    "for file in file_lists:\n",
    "    ensure_directory_exists(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Days to work on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 752 µs (started: 2022-11-16 12:54:40 +00:00)\n"
     ]
    }
   ],
   "source": [
    "days = list(range(0, 23 + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples to take:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 502 µs (started: 2022-11-16 12:54:40 +00:00)\n"
     ]
    }
   ],
   "source": [
    "train_samples = [\n",
    "    10000, 30000,  # tens of thousands\n",
    "    100000, 300000,  # hundreds of thousands\n",
    "    1000000, 3000000,  # millions\n",
    "    10000000, 30000000,  # tens of millions\n",
    "    100000000, 300000000,  # hundreds of millions\n",
    "    1000000000, 3000000000,  # billions\n",
    "]\n",
    "test_samples = [1000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark configuration and initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 586 µs (started: 2022-11-16 12:54:40 +00:00)\n"
     ]
    }
   ],
   "source": [
    "total_cores = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 775 µs (started: 2022-11-16 12:54:41 +00:00)\n"
     ]
    }
   ],
   "source": [
    "executor_cores = 4\n",
    "executor_instances = total_cores / executor_cores\n",
    "memory_per_core = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 906 µs (started: 2022-11-16 12:54:41 +00:00)\n"
     ]
    }
   ],
   "source": [
    "app_name = 'Criteo experiment'\n",
    "\n",
    "master = 'yarn'\n",
    "\n",
    "settings = {\n",
    "    'spark.network.timeout': '600',\n",
    "    \n",
    "    'spark.driver.cores': '16',\n",
    "    'spark.driver.maxResultSize': '16G',\n",
    "    'spark.driver.memory': '32G',\n",
    "    \n",
    "    'spark.executor.cores': str(executor_cores),\n",
    "    'spark.executor.instances': str(executor_instances),\n",
    "    'spark.executor.memory': str(memory_per_core * executor_cores) + 'G',\n",
    "    \n",
    "    'spark.speculation': 'true',\n",
    "    'spark.yarn.queue': 'root.HungerGames',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/16 12:54:42 WARN Utils: Your hostname, oneflow-27 resolves to a loopback address: 127.0.1.1; using 192.168.1.27 instead (on interface ens121f0)\n",
      "22/11/16 12:54:42 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/16 12:54:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/11/16 12:54:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "time: 2.84 s (started: 2022-11-16 12:54:41 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/data/dataset/fengwen/script/data/spark-3.3.1-bin-hadoop3-scala2.13')\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext('local','pyspark')\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/home/fengwen/miniconda3/envs/spark/bin/jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = \" --ip=0.0.0.0 --port=7777\"\n",
    "# jupyter: /home/fengwen/miniconda3/envs/spark/bin/jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 108 ms (started: 2022-11-16 12:54:44 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "builder = SparkSession.builder\n",
    "\n",
    "builder.appName(app_name)\n",
    "builder.master(master)\n",
    "for k, v in settings.items():\n",
    "    builder.config(k, v)\n",
    "\n",
    "spark = builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sc.setLogLevel('ERROR')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.18 ms (started: 2022-11-16 12:54:44 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "from importlib import reload # 添加\n",
    "logging.shutdown()            # 添加\n",
    "reload(logging)              # 在 reload(logging) 前添加两行代码\n",
    "\n",
    "\n",
    "handler = logging.StreamHandler(stream=sys.stdout)\n",
    "formatter = logging.Formatter('[%(asctime)s] %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "ensure_directory_exists(local_runtime_path)\n",
    "file_handler = logging.FileHandler(filename=os.path.join(local_runtime_path, 'mylog.log'), mode='a')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.addHandler(handler)\n",
    "logger.addHandler(file_handler)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:54:44,474] Spark version: 3.3.1.\n",
      "time: 1.76 ms (started: 2022-11-16 12:54:44 +00:00)\n"
     ]
    }
   ],
   "source": [
    "logger.info('Spark version: %s.', spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation 数据准备\n",
    "[_(back to toc)_](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poor man's HDFS API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 555 µs (started: 2022-11-16 12:54:44 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def hdfs_exists(path):\n",
    "    l = !hadoop fs -ls $path 2>/dev/null\n",
    "    return len(l) != 0\n",
    "\n",
    "def hdfs_success(path):\n",
    "    return hdfs_exists(os.path.join(path, '_SUCCESS'))\n",
    "\n",
    "def hdfs_delete(path, recurse=False):\n",
    "    if recurse:\n",
    "        _ = !hadoop fs -rm -r $path\n",
    "    else:\n",
    "        _ = !hadoop fs -rm $path\n",
    "\n",
    "def hdfs_get(remote_path, local_path):\n",
    "    remote_path_glob = os.path.join(remote_path, 'part-*')\n",
    "    _ = !hadoop fs -cat $remote_path_glob >$local_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load RDDs from one place and save them to another converted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 638 µs (started: 2022-11-16 12:54:44 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def convert_chunked_data(input_path_template, output_path_template, chunks, load_rdd, convert_row, transform_rdd=None):\n",
    "    for chunk in chunks:\n",
    "        input_path = input_path_template.format(chunk)\n",
    "        output_path = output_path_template.format(chunk)\n",
    "\n",
    "        if hdfs_success(output_path):\n",
    "            logger.info('Chunk \"%s\" is already converted and saved to \"%s\", skipping.', chunk, output_path)\n",
    "            continue\n",
    "\n",
    "        logger.info('Reading chunk \"%s\" data from \"%s\".', chunk, input_path)\n",
    "        rdd = load_rdd(input_path)\n",
    "\n",
    "        if hdfs_exists(output_path):\n",
    "            logger.info('Cleaning \"%s\".', output_path)\n",
    "            hdfs_delete(output_path, recurse=True)\n",
    "\n",
    "        logger.info('Processing and saving to \"%s\".', output_path)\n",
    "        rdd = rdd.map(convert_row)\n",
    "        \n",
    "        if transform_rdd is not None:\n",
    "            rdd = transform_rdd(rdd)\n",
    "        \n",
    "        rdd.saveAsTextFile(output_path)\n",
    "\n",
    "        logger.info('Done with chunk \"%s\".', chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criteo → LibSVM\n",
    "[_(back to toc)_](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criteo RDD is actually a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 305 µs (started: 2022-11-16 12:54:44 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def load_criteo_rdd(path):\n",
    "    return (\n",
    "        spark\n",
    "        .read\n",
    "        .option('header', 'false')\n",
    "        .option('inferSchema', 'true')\n",
    "        .option('delimiter', '\\t')\n",
    "        .csv(path)\n",
    "        .rdd\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply add an index to each existing column except the first one which is a target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.69 ms (started: 2022-11-16 12:54:44 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def criteo_to_libsvm(row):\n",
    "    return (\n",
    "        str(row[0])\n",
    "        + ' '\n",
    "        + ' '.join(\n",
    "            [\n",
    "                # integer features\n",
    "                str(i) + ':' + str(row[i])\n",
    "                for i in range(1, 13 + 1)\n",
    "                if row[i] is not None\n",
    "            ] + [\n",
    "                # string features converted from hex to int\n",
    "                str(i) + ':' + str(int(row[i], 16))\n",
    "                for i in range(14, 39 + 1)\n",
    "                if row[i] is not None\n",
    "            ]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do it for all days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:54:44,998] Reading chunk \"0\" data from \"criteo/plain/day0\".\n",
      "[2022-11-16 12:54:49,220] Processing and saving to \"criteo/libsvm/day0\".\n",
      "[2022-11-16 12:54:49,961] Done with chunk \"0\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:54:49,975] Reading chunk \"1\" data from \"criteo/plain/day1\".\n",
      "[2022-11-16 12:54:50,243] Processing and saving to \"criteo/libsvm/day1\".\n",
      "[2022-11-16 12:54:50,379] Done with chunk \"1\".\n",
      "[2022-11-16 12:54:50,391] Reading chunk \"2\" data from \"criteo/plain/day2\".\n",
      "[2022-11-16 12:54:50,584] Processing and saving to \"criteo/libsvm/day2\".\n",
      "[2022-11-16 12:54:50,696] Done with chunk \"2\".\n",
      "[2022-11-16 12:54:50,704] Reading chunk \"3\" data from \"criteo/plain/day3\".\n",
      "[2022-11-16 12:54:50,898] Processing and saving to \"criteo/libsvm/day3\".\n",
      "[2022-11-16 12:54:51,035] Done with chunk \"3\".\n",
      "[2022-11-16 12:54:51,045] Reading chunk \"4\" data from \"criteo/plain/day4\".\n",
      "[2022-11-16 12:54:51,244] Processing and saving to \"criteo/libsvm/day4\".\n",
      "[2022-11-16 12:54:51,354] Done with chunk \"4\".\n",
      "[2022-11-16 12:54:51,365] Reading chunk \"5\" data from \"criteo/plain/day5\".\n",
      "[2022-11-16 12:54:51,555] Processing and saving to \"criteo/libsvm/day5\".\n",
      "[2022-11-16 12:54:51,661] Done with chunk \"5\".\n",
      "[2022-11-16 12:54:51,671] Reading chunk \"6\" data from \"criteo/plain/day6\".\n",
      "[2022-11-16 12:54:51,852] Processing and saving to \"criteo/libsvm/day6\".\n",
      "[2022-11-16 12:54:51,966] Done with chunk \"6\".\n",
      "[2022-11-16 12:54:51,976] Reading chunk \"7\" data from \"criteo/plain/day7\".\n",
      "[2022-11-16 12:54:52,153] Processing and saving to \"criteo/libsvm/day7\".\n",
      "[2022-11-16 12:54:52,245] Done with chunk \"7\".\n",
      "[2022-11-16 12:54:52,257] Reading chunk \"8\" data from \"criteo/plain/day8\".\n",
      "[2022-11-16 12:54:52,399] Processing and saving to \"criteo/libsvm/day8\".\n",
      "[2022-11-16 12:54:52,492] Done with chunk \"8\".\n",
      "[2022-11-16 12:54:52,503] Reading chunk \"9\" data from \"criteo/plain/day9\".\n",
      "[2022-11-16 12:54:52,676] Processing and saving to \"criteo/libsvm/day9\".\n",
      "[2022-11-16 12:54:52,816] Done with chunk \"9\".\n",
      "[2022-11-16 12:54:52,828] Reading chunk \"10\" data from \"criteo/plain/day10\".\n",
      "[2022-11-16 12:54:53,001] Processing and saving to \"criteo/libsvm/day10\".\n",
      "[2022-11-16 12:54:53,103] Done with chunk \"10\".\n",
      "[2022-11-16 12:54:53,115] Reading chunk \"11\" data from \"criteo/plain/day11\".\n",
      "[2022-11-16 12:54:53,256] Processing and saving to \"criteo/libsvm/day11\".\n",
      "[2022-11-16 12:54:53,347] Done with chunk \"11\".\n",
      "[2022-11-16 12:54:53,360] Reading chunk \"12\" data from \"criteo/plain/day12\".\n",
      "[2022-11-16 12:54:53,506] Processing and saving to \"criteo/libsvm/day12\".\n",
      "[2022-11-16 12:54:53,638] Done with chunk \"12\".\n",
      "[2022-11-16 12:54:53,650] Reading chunk \"13\" data from \"criteo/plain/day13\".\n",
      "[2022-11-16 12:54:53,820] Processing and saving to \"criteo/libsvm/day13\".\n",
      "[2022-11-16 12:54:53,909] Done with chunk \"13\".\n",
      "[2022-11-16 12:54:53,920] Reading chunk \"14\" data from \"criteo/plain/day14\".\n",
      "[2022-11-16 12:54:54,086] Processing and saving to \"criteo/libsvm/day14\".\n",
      "[2022-11-16 12:54:54,181] Done with chunk \"14\".\n",
      "[2022-11-16 12:54:54,193] Reading chunk \"15\" data from \"criteo/plain/day15\".\n",
      "[2022-11-16 12:54:54,329] Processing and saving to \"criteo/libsvm/day15\".\n",
      "[2022-11-16 12:54:54,449] Done with chunk \"15\".\n",
      "[2022-11-16 12:54:54,459] Reading chunk \"16\" data from \"criteo/plain/day16\".\n",
      "[2022-11-16 12:54:54,589] Processing and saving to \"criteo/libsvm/day16\".\n",
      "[2022-11-16 12:54:54,687] Done with chunk \"16\".\n",
      "[2022-11-16 12:54:54,698] Reading chunk \"17\" data from \"criteo/plain/day17\".\n",
      "[2022-11-16 12:54:54,848] Processing and saving to \"criteo/libsvm/day17\".\n",
      "[2022-11-16 12:54:54,930] Done with chunk \"17\".\n",
      "[2022-11-16 12:54:54,941] Reading chunk \"18\" data from \"criteo/plain/day18\".\n",
      "[2022-11-16 12:54:55,070] Processing and saving to \"criteo/libsvm/day18\".\n",
      "[2022-11-16 12:54:55,193] Done with chunk \"18\".\n",
      "[2022-11-16 12:54:55,206] Reading chunk \"19\" data from \"criteo/plain/day19\".\n",
      "[2022-11-16 12:54:55,346] Processing and saving to \"criteo/libsvm/day19\".\n",
      "[2022-11-16 12:54:55,437] Done with chunk \"19\".\n",
      "[2022-11-16 12:54:55,448] Reading chunk \"20\" data from \"criteo/plain/day20\".\n",
      "[2022-11-16 12:54:55,595] Processing and saving to \"criteo/libsvm/day20\".\n",
      "[2022-11-16 12:54:55,688] Done with chunk \"20\".\n",
      "[2022-11-16 12:54:55,698] Reading chunk \"21\" data from \"criteo/plain/day21\".\n",
      "[2022-11-16 12:54:55,853] Processing and saving to \"criteo/libsvm/day21\".\n",
      "[2022-11-16 12:54:55,987] Done with chunk \"21\".\n",
      "[2022-11-16 12:54:55,999] Reading chunk \"22\" data from \"criteo/plain/day22\".\n",
      "[2022-11-16 12:54:56,144] Processing and saving to \"criteo/libsvm/day22\".\n",
      "[2022-11-16 12:54:56,231] Done with chunk \"22\".\n",
      "[2022-11-16 12:54:56,241] Reading chunk \"23\" data from \"criteo/plain/day23\".\n",
      "[2022-11-16 12:54:56,400] Processing and saving to \"criteo/libsvm/day23\".\n",
      "[2022-11-16 12:54:56,474] Done with chunk \"23\".\n",
      "time: 11.5 s (started: 2022-11-16 12:54:44 +00:00)\n"
     ]
    }
   ],
   "source": [
    "convert_chunked_data(criteo_day_template, libsvm_day_template, days, load_criteo_rdd, criteo_to_libsvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LibSVM → Train and test (sampling)\n",
    "[_(back to toc)_](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's name samples as their shortened \"engineering\" notation - e.g. 1e5 is 100k etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 803 µs (started: 2022-11-16 12:54:56 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def sample_name(sample):\n",
    "    return str(sample)[::-1].replace('000', 'k')[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data, sample a bit more than needed and cut at exact desired number of lines by zipping with index and filtering upto required index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.46 ms (started: 2022-11-16 12:54:56 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "oversample = 1.03\n",
    "sampled_partitions = 256\n",
    "\n",
    "\n",
    "def sample_and_save(input_path_template, output_path_template, days, samples):\n",
    "    union = None\n",
    "    union_count = None\n",
    "    \n",
    "    for sample in samples:\n",
    "        name = sample_name(sample)\n",
    "        output_path = output_path_template.format(name)\n",
    "        \n",
    "        if hdfs_success(output_path):\n",
    "            logger.info('Sample \"%s\" is already written to \"%s\", skipping.', sample, output_path)\n",
    "            continue\n",
    "            \n",
    "        logger.info('Preparing to write sample to \"%s\".', output_path)\n",
    "        \n",
    "        if union is None:\n",
    "            rdds = map(lambda day: sc.textFile(input_path_template.format(day)), days)\n",
    "            union = reduce(lambda left, right: left.union(right), rdds)\n",
    "\n",
    "            union_count = union.count()\n",
    "            logger.info('Total number of lines for days \"%s\" is \"%s\".', days, union_count)\n",
    "            \n",
    "        ratio = float(sample) / union_count\n",
    "        \n",
    "        sampled_union = (\n",
    "            union\n",
    "            .sample(False, min(1.0, oversample * ratio))\n",
    "            .zipWithIndex()\n",
    "            .filter(lambda z: z[1] < sample)\n",
    "            .map(lambda z: z[0])\n",
    "        )\n",
    "        \n",
    "        if hdfs_exists(output_path):\n",
    "            logger.info('Cleaning \"%s\".', output_path)\n",
    "            hdfs_delete(output_path, recurse=True)\n",
    "            \n",
    "        logger.info('Writing sample \"%s\" to \"%s\".', sample, output_path)\n",
    "        sampled_union.coalesce(sampled_partitions).saveAsTextFile(output_path)\n",
    "        \n",
    "        logger.info('Saved \"%s\" lines to \"%s\".', sc.textFile(output_path).count(), output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample all LibSVM data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:54:56,792] Preparing to write sample to \"criteo/libsvm/test/1kk\".\n",
      "[2022-11-16 12:54:57,009] Total number of lines for days \"[23]\" is \"20\".\n",
      "[2022-11-16 12:54:57,017] Writing sample \"1000000\" to \"criteo/libsvm/test/1kk\".\n",
      "[2022-11-16 12:54:57,179] Saved \"20\" lines to \"criteo/libsvm/test/1kk\".\n",
      "time: 401 ms (started: 2022-11-16 12:54:56 +00:00)\n"
     ]
    }
   ],
   "source": [
    "sample_and_save(libsvm_day_template, libsvm_test_template, days[-1:], test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:54:57,290] Preparing to write sample to \"criteo/libsvm/train/10k\".\n",
      "[2022-11-16 12:54:58,451] Total number of lines for days \"[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\" is \"460\".\n",
      "[2022-11-16 12:54:58,969] Writing sample \"10000\" to \"criteo/libsvm/train/10k\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:00,344] Saved \"460\" lines to \"criteo/libsvm/train/10k\".\n",
      "[2022-11-16 12:55:00,356] Preparing to write sample to \"criteo/libsvm/train/30k\".\n",
      "[2022-11-16 12:55:00,891] Writing sample \"30000\" to \"criteo/libsvm/train/30k\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:02,237] Saved \"460\" lines to \"criteo/libsvm/train/30k\".\n",
      "[2022-11-16 12:55:02,250] Preparing to write sample to \"criteo/libsvm/train/100k\".\n",
      "[2022-11-16 12:55:02,693] Writing sample \"100000\" to \"criteo/libsvm/train/100k\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:04,061] Saved \"460\" lines to \"criteo/libsvm/train/100k\".\n",
      "[2022-11-16 12:55:04,071] Preparing to write sample to \"criteo/libsvm/train/300k\".\n",
      "[2022-11-16 12:55:04,578] Writing sample \"300000\" to \"criteo/libsvm/train/300k\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:05,881] Saved \"460\" lines to \"criteo/libsvm/train/300k\".\n",
      "[2022-11-16 12:55:05,894] Preparing to write sample to \"criteo/libsvm/train/1kk\".\n",
      "[2022-11-16 12:55:06,386] Writing sample \"1000000\" to \"criteo/libsvm/train/1kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:07,682] Saved \"460\" lines to \"criteo/libsvm/train/1kk\".\n",
      "[2022-11-16 12:55:07,693] Preparing to write sample to \"criteo/libsvm/train/3kk\".\n",
      "[2022-11-16 12:55:08,171] Writing sample \"3000000\" to \"criteo/libsvm/train/3kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:09,513] Saved \"460\" lines to \"criteo/libsvm/train/3kk\".\n",
      "[2022-11-16 12:55:09,526] Preparing to write sample to \"criteo/libsvm/train/10kk\".\n",
      "[2022-11-16 12:55:09,991] Writing sample \"10000000\" to \"criteo/libsvm/train/10kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:11,305] Saved \"460\" lines to \"criteo/libsvm/train/10kk\".\n",
      "[2022-11-16 12:55:11,318] Preparing to write sample to \"criteo/libsvm/train/30kk\".\n",
      "[2022-11-16 12:55:11,805] Writing sample \"30000000\" to \"criteo/libsvm/train/30kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:13,060] Saved \"460\" lines to \"criteo/libsvm/train/30kk\".\n",
      "[2022-11-16 12:55:13,069] Preparing to write sample to \"criteo/libsvm/train/100kk\".\n",
      "[2022-11-16 12:55:13,520] Writing sample \"100000000\" to \"criteo/libsvm/train/100kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:14,878] Saved \"460\" lines to \"criteo/libsvm/train/100kk\".\n",
      "[2022-11-16 12:55:14,892] Preparing to write sample to \"criteo/libsvm/train/300kk\".\n",
      "[2022-11-16 12:55:15,388] Writing sample \"300000000\" to \"criteo/libsvm/train/300kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:16,771] Saved \"460\" lines to \"criteo/libsvm/train/300kk\".\n",
      "[2022-11-16 12:55:16,783] Preparing to write sample to \"criteo/libsvm/train/1kkk\".\n",
      "[2022-11-16 12:55:17,296] Writing sample \"1000000000\" to \"criteo/libsvm/train/1kkk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:18,576] Saved \"460\" lines to \"criteo/libsvm/train/1kkk\".\n",
      "[2022-11-16 12:55:18,589] Preparing to write sample to \"criteo/libsvm/train/3kkk\".\n",
      "[2022-11-16 12:55:19,010] Writing sample \"3000000000\" to \"criteo/libsvm/train/3kkk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:20,341] Saved \"460\" lines to \"criteo/libsvm/train/3kkk\".\n",
      "time: 23.1 s (started: 2022-11-16 12:54:57 +00:00)\n"
     ]
    }
   ],
   "source": [
    "sample_and_save(libsvm_day_template, libsvm_train_template, days[:-1], train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LibSVM train and test → VW train and test\n",
    "[_(back to toc)_](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LibSVM RDD is a text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.16 ms (started: 2022-11-16 12:55:20 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def load_libsvm_rdd(path):\n",
    "    return sc.textFile(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion is trivial - we only have to map target to {-1, 1} and convert categorical features to VW feature names as a whole:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.71 ms (started: 2022-11-16 12:55:20 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def libsvm_to_vw(line):\n",
    "    parts = line.split(' ')\n",
    "    parts[0] = '1 |' if parts[0] == '1' else '-1 |'\n",
    "    for i in range(1, len(parts)):\n",
    "        index, _, value = parts[i].partition(':')\n",
    "        if int(index) >= 14:\n",
    "            parts[i] = index + '_' + value\n",
    "    return ' '.join(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, data for VW should be well shuffled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.1 ms (started: 2022-11-16 12:55:20 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "\n",
    "def calculate_hash(something):\n",
    "    m = hashlib.md5()\n",
    "    m.update(str(something).encode(\"utf-8\"))\n",
    "    return m.hexdigest()\n",
    "\n",
    "def random_sort(rdd):\n",
    "    return (\n",
    "        rdd\n",
    "        .zipWithIndex()\n",
    "        .sortBy(lambda z: calculate_hash(z[1]))\n",
    "        .map(lambda z: z[0])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all LibSVM samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:20,818] Reading chunk \"1kk\" data from \"criteo/libsvm/test/1kk\".\n",
      "[2022-11-16 12:55:20,848] Processing and saving to \"criteo/vw/test/1kk\".\n",
      "[2022-11-16 12:55:20,953] Done with chunk \"1kk\".\n",
      "time: 150 ms (started: 2022-11-16 12:55:20 +00:00)\n"
     ]
    }
   ],
   "source": [
    "convert_chunked_data(libsvm_test_template, vw_test_template, [sample_name(sample) for sample in test_samples], load_libsvm_rdd, libsvm_to_vw, transform_rdd=random_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:21,119] Reading chunk \"10k\" data from \"criteo/libsvm/train/10k\".\n",
      "[2022-11-16 12:55:21,152] Processing and saving to \"criteo/vw/train/10k\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 117:=============================================>         (19 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:24,461] Done with chunk \"10k\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:24,473] Reading chunk \"30k\" data from \"criteo/libsvm/train/30k\".\n",
      "[2022-11-16 12:55:24,506] Processing and saving to \"criteo/vw/train/30k\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 121:========================================>              (17 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:27,514] Done with chunk \"30k\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:27,526] Reading chunk \"100k\" data from \"criteo/libsvm/train/100k\".\n",
      "[2022-11-16 12:55:27,562] Processing and saving to \"criteo/vw/train/100k\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 126:==================================================>    (21 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:30,574] Done with chunk \"100k\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:30,584] Reading chunk \"300k\" data from \"criteo/libsvm/train/300k\".\n",
      "[2022-11-16 12:55:30,603] Processing and saving to \"criteo/vw/train/300k\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 131:========================================>              (17 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:33,421] Done with chunk \"300k\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:33,435] Reading chunk \"1kk\" data from \"criteo/libsvm/train/1kk\".\n",
      "[2022-11-16 12:55:33,469] Processing and saving to \"criteo/vw/train/1kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 136:===============================================>       (20 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:36,347] Done with chunk \"1kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:36,361] Reading chunk \"3kk\" data from \"criteo/libsvm/train/3kk\".\n",
      "[2022-11-16 12:55:36,392] Processing and saving to \"criteo/vw/train/3kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 141:========================================>              (17 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:39,302] Done with chunk \"3kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:39,314] Reading chunk \"10kk\" data from \"criteo/libsvm/train/10kk\".\n",
      "[2022-11-16 12:55:39,347] Processing and saving to \"criteo/vw/train/10kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 146:===========================================>           (18 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:42,238] Done with chunk \"10kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:42,250] Reading chunk \"30kk\" data from \"criteo/libsvm/train/30kk\".\n",
      "[2022-11-16 12:55:42,285] Processing and saving to \"criteo/vw/train/30kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 151:==================================================>    (21 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:45,170] Done with chunk \"30kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:45,182] Reading chunk \"100kk\" data from \"criteo/libsvm/train/100kk\".\n",
      "[2022-11-16 12:55:45,213] Processing and saving to \"criteo/vw/train/100kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 156:====================================================>  (22 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:48,049] Done with chunk \"100kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:48,062] Reading chunk \"300kk\" data from \"criteo/libsvm/train/300kk\".\n",
      "[2022-11-16 12:55:48,099] Processing and saving to \"criteo/vw/train/300kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 161:==================================================>    (21 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:50,962] Done with chunk \"300kk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:50,976] Reading chunk \"1kkk\" data from \"criteo/libsvm/train/1kkk\".\n",
      "[2022-11-16 12:55:51,008] Processing and saving to \"criteo/vw/train/1kkk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 166:=============================================>         (19 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:53,871] Done with chunk \"1kkk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:53,885] Reading chunk \"3kkk\" data from \"criteo/libsvm/train/3kkk\".\n",
      "[2022-11-16 12:55:53,917] Processing and saving to \"criteo/vw/train/3kkk\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 171:====================================================>  (22 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:56,716] Done with chunk \"3kkk\".\n",
      "time: 35.6 s (started: 2022-11-16 12:55:21 +00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "convert_chunked_data(libsvm_train_template, vw_train_template, [sample_name(sample) for sample in train_samples], load_libsvm_rdd, libsvm_to_vw, transform_rdd=random_sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark is no longer needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 876 ms (started: 2022-11-16 12:55:56 +00:00)\n"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local data\n",
    "[_(back to toc)_](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all sampled data to local directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.16 ms (started: 2022-11-16 12:55:57 +00:00)\n"
     ]
    }
   ],
   "source": [
    "ensure_directory_exists(local_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.88 ms (started: 2022-11-16 12:55:57 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def count_lines(path):\n",
    "    lines = 0\n",
    "    with open(path) as f:\n",
    "        for i, _ in enumerate(f):\n",
    "            lines = i\n",
    "        return lines + 1\n",
    "\n",
    "def download_data(remote_template, local_template, samples):\n",
    "    for sample in samples:\n",
    "        name = sample_name(sample)\n",
    "        remote_path = remote_template.format(name)\n",
    "        local_path = local_template.format(name)\n",
    "        if os.path.exists(local_path):\n",
    "            count = count_lines(local_path)\n",
    "            if count == sample:\n",
    "                logger.info('File \"%s\" is already loaded, skipping.', local_path)\n",
    "                continue\n",
    "            else:\n",
    "                logger.info('File \"%s\" already exists but number of lines \"%s\" is wrong (must be \"%s\"), reloading.', local_path, count, sample)\n",
    "        logger.info('Loading file \"%s\" as local file \"%s\".', remote_path, local_path)\n",
    "        hdfs_get(remote_path, local_path)\n",
    "        count = count_lines(local_path)\n",
    "        logger.info('File loaded to \"%s\", number of lines is \"%s\".', local_path, count)\n",
    "        # assert count == sample, 'File \"{}\" contains wrong number of lines \"{}\" (must be \"{}\").'.format(local_path, count, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:58,038] Loading file \"criteo/libsvm/test/1kk\" as local file \"criteo/data/data.test.1kk.libsvm\".\n",
      "[2022-11-16 12:55:58,052] File loaded to \"criteo/data/data.test.1kk.libsvm\", number of lines is \"1\".\n",
      "time: 15.6 ms (started: 2022-11-16 12:55:58 +00:00)\n"
     ]
    }
   ],
   "source": [
    "download_data(libsvm_test_template, local_libsvm_test_template, test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:58,154] Loading file \"criteo/libsvm/train/10k\" as local file \"criteo/data/data.train.10k.libsvm\".\n",
      "[2022-11-16 12:55:58,168] File loaded to \"criteo/data/data.train.10k.libsvm\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,170] Loading file \"criteo/libsvm/train/30k\" as local file \"criteo/data/data.train.30k.libsvm\".\n",
      "[2022-11-16 12:55:58,181] File loaded to \"criteo/data/data.train.30k.libsvm\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,182] Loading file \"criteo/libsvm/train/100k\" as local file \"criteo/data/data.train.100k.libsvm\".\n",
      "[2022-11-16 12:55:58,191] File loaded to \"criteo/data/data.train.100k.libsvm\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,193] Loading file \"criteo/libsvm/train/300k\" as local file \"criteo/data/data.train.300k.libsvm\".\n",
      "[2022-11-16 12:55:58,203] File loaded to \"criteo/data/data.train.300k.libsvm\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,204] Loading file \"criteo/libsvm/train/1kk\" as local file \"criteo/data/data.train.1kk.libsvm\".\n",
      "[2022-11-16 12:55:58,217] File loaded to \"criteo/data/data.train.1kk.libsvm\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,219] Loading file \"criteo/libsvm/train/3kk\" as local file \"criteo/data/data.train.3kk.libsvm\".\n",
      "[2022-11-16 12:55:58,231] File loaded to \"criteo/data/data.train.3kk.libsvm\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,233] Loading file \"criteo/libsvm/train/10kk\" as local file \"criteo/data/data.train.10kk.libsvm\".\n",
      "[2022-11-16 12:55:58,241] File loaded to \"criteo/data/data.train.10kk.libsvm\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,242] Loading file \"criteo/libsvm/train/30kk\" as local file \"criteo/data/data.train.30kk.libsvm\".\n",
      "[2022-11-16 12:55:58,249] File loaded to \"criteo/data/data.train.30kk.libsvm\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,251] Loading file \"criteo/libsvm/train/100kk\" as local file \"criteo/data/data.train.100kk.libsvm\".\n",
      "[2022-11-16 12:55:58,258] File loaded to \"criteo/data/data.train.100kk.libsvm\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,260] Loading file \"criteo/libsvm/train/300kk\" as local file \"criteo/data/data.train.300kk.libsvm\".\n",
      "[2022-11-16 12:55:58,269] File loaded to \"criteo/data/data.train.300kk.libsvm\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,270] Loading file \"criteo/libsvm/train/1kkk\" as local file \"criteo/data/data.train.1kkk.libsvm\".\n",
      "[2022-11-16 12:55:58,278] File loaded to \"criteo/data/data.train.1kkk.libsvm\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,280] Loading file \"criteo/libsvm/train/3kkk\" as local file \"criteo/data/data.train.3kkk.libsvm\".\n",
      "[2022-11-16 12:55:58,290] File loaded to \"criteo/data/data.train.3kkk.libsvm\", number of lines is \"1\".\n",
      "time: 139 ms (started: 2022-11-16 12:55:58 +00:00)\n"
     ]
    }
   ],
   "source": [
    "download_data(libsvm_train_template, local_libsvm_train_template, train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:58,384] Loading file \"criteo/vw/test/1kk\" as local file \"criteo/data/data.test.1kk.vw\".\n",
      "[2022-11-16 12:55:58,398] File loaded to \"criteo/data/data.test.1kk.vw\", number of lines is \"1\".\n",
      "time: 16.7 ms (started: 2022-11-16 12:55:58 +00:00)\n"
     ]
    }
   ],
   "source": [
    "download_data(vw_test_template, local_vw_test_template, test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:58,502] Loading file \"criteo/vw/train/10k\" as local file \"criteo/data/data.train.10k.vw\".\n",
      "[2022-11-16 12:55:58,515] File loaded to \"criteo/data/data.train.10k.vw\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,517] Loading file \"criteo/vw/train/30k\" as local file \"criteo/data/data.train.30k.vw\".\n",
      "[2022-11-16 12:55:58,525] File loaded to \"criteo/data/data.train.30k.vw\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,526] Loading file \"criteo/vw/train/100k\" as local file \"criteo/data/data.train.100k.vw\".\n",
      "[2022-11-16 12:55:58,533] File loaded to \"criteo/data/data.train.100k.vw\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,535] Loading file \"criteo/vw/train/300k\" as local file \"criteo/data/data.train.300k.vw\".\n",
      "[2022-11-16 12:55:58,542] File loaded to \"criteo/data/data.train.300k.vw\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,543] Loading file \"criteo/vw/train/1kk\" as local file \"criteo/data/data.train.1kk.vw\".\n",
      "[2022-11-16 12:55:58,551] File loaded to \"criteo/data/data.train.1kk.vw\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,553] Loading file \"criteo/vw/train/3kk\" as local file \"criteo/data/data.train.3kk.vw\".\n",
      "[2022-11-16 12:55:58,560] File loaded to \"criteo/data/data.train.3kk.vw\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,562] Loading file \"criteo/vw/train/10kk\" as local file \"criteo/data/data.train.10kk.vw\".\n",
      "[2022-11-16 12:55:58,572] File loaded to \"criteo/data/data.train.10kk.vw\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,573] Loading file \"criteo/vw/train/30kk\" as local file \"criteo/data/data.train.30kk.vw\".\n",
      "[2022-11-16 12:55:58,582] File loaded to \"criteo/data/data.train.30kk.vw\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,584] Loading file \"criteo/vw/train/100kk\" as local file \"criteo/data/data.train.100kk.vw\".\n",
      "[2022-11-16 12:55:58,595] File loaded to \"criteo/data/data.train.100kk.vw\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,597] Loading file \"criteo/vw/train/300kk\" as local file \"criteo/data/data.train.300kk.vw\".\n",
      "[2022-11-16 12:55:58,608] File loaded to \"criteo/data/data.train.300kk.vw\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,610] Loading file \"criteo/vw/train/1kkk\" as local file \"criteo/data/data.train.1kkk.vw\".\n",
      "[2022-11-16 12:55:58,621] File loaded to \"criteo/data/data.train.1kkk.vw\", number of lines is \"1\".\n",
      "[2022-11-16 12:55:58,622] Loading file \"criteo/vw/train/3kkk\" as local file \"criteo/data/data.train.3kkk.vw\".\n",
      "[2022-11-16 12:55:58,634] File loaded to \"criteo/data/data.train.3kkk.vw\", number of lines is \"1\".\n",
      "time: 135 ms (started: 2022-11-16 12:55:58 +00:00)\n"
     ]
    }
   ],
   "source": [
    "download_data(vw_train_template, local_vw_train_template, train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local training\n",
    "[_(back to toc)_](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring model quality and ML engine technical metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 396 ms (started: 2022-11-16 12:55:58 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "import sys \n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    log_loss,\n",
    "    roc_curve,\n",
    ")\n",
    "\n",
    "\n",
    "def measure(engine, sample, test_file, time_file, predictions_file):\n",
    "    \n",
    "    def get_last_in_line(s):\n",
    "        return s.rstrip().split( )[-1]\n",
    "\n",
    "    def parse_elapsed_time(s):\n",
    "        return reduce(lambda a, b: a * 60 + b, map(float, get_last_in_line(s).split(':')))\n",
    "\n",
    "    def parse_max_memory(s):\n",
    "        return int(get_last_in_line(s)) * 1024\n",
    "\n",
    "    def parse_cpu(s):\n",
    "        return float(get_last_in_line(s).rstrip('%')) / 100 \n",
    "\n",
    "\n",
    "    elapsed = -1\n",
    "    memory = -1\n",
    "    cpu = -1\n",
    "\n",
    "    with open(time_file, 'rb') as f:\n",
    "        for line in f:\n",
    "            if 'Elapsed (wall clock) time' in line:\n",
    "                elapsed = parse_elapsed_time(line)\n",
    "            elif 'Maximum resident set size' in line:\n",
    "                memory = parse_max_memory(line)\n",
    "            elif 'Percent of CPU' in line:\n",
    "                cpu = parse_cpu(line)\n",
    "\n",
    "    with open(test_file, 'rb') as f:\n",
    "        labels = [line.rstrip().split(' ')[0] == '1' for line in f]\n",
    "\n",
    "    with open(predictions_file, 'rb') as f:\n",
    "        scores = [float(line.rstrip().split(' ')[0]) for line in f]\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(labels, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    ll = log_loss(labels, scores)\n",
    "    \n",
    "    figure = pyplot.figure(figsize=(6, 6))\n",
    "    pyplot.plot(fpr, tpr, linewidth=2.0)\n",
    "    pyplot.plot([0, 1], [0, 1], 'k--')\n",
    "    pyplot.xlabel('FPR')\n",
    "    pyplot.ylabel('TPR')\n",
    "    pyplot.title('{} {} - {:.3f} ROC AUC'.format(engine, sample_name(sample), roc_auc))\n",
    "    pyplot.show()\n",
    "\n",
    "    return {\n",
    "        'Engine': engine,\n",
    "        'Train size': sample,\n",
    "        'ROC AUC': roc_auc,\n",
    "        'Log loss': ll,\n",
    "        'Train time': elapsed,\n",
    "        'Maximum memory': memory,\n",
    "        'CPU load': cpu,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings for VW & XGBoost and how to run them; I use (a little bit patched for correctness sake) GNU Time to measure running time, CPU load and memory consumption; configurations for VW & XGBoost are obtained via Hyperopt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.27 ms (started: 2022-11-16 12:55:59 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def get_time_command_and_file(train_file):\n",
    "    time_file = train_file + '.time'\n",
    "    print(\"time_file\", time_file)\n",
    "    return [\n",
    "        # '/usr/local/bin/time',\n",
    "        '/usr/bin/time',\n",
    "        '-v',\n",
    "        '--output=' + time_file,\n",
    "    ], time_file\n",
    "\n",
    "def get_vw_commands_and_predictions_file(train_file, test_file):\n",
    "    model_file = train_file + '.model'\n",
    "    predictions_file = test_file + '.predictions'\n",
    "    return [\n",
    "        'vw83',\n",
    "        '--link=logistic',\n",
    "        '--loss_function=logistic',\n",
    "        '-b', '29',\n",
    "        '-l', '0.3',\n",
    "        '--initial_t', '1',\n",
    "        '--decay_learning_rate', '0.5',\n",
    "        '--power_t', '0.5',\n",
    "        '--l1', '1e-15',\n",
    "        '--l2', '0',\n",
    "        '-d', train_file,\n",
    "        '-f', model_file,\n",
    "    ], [\n",
    "        'vw83',\n",
    "        '--loss_function=logistic',\n",
    "        '-t',\n",
    "        '-i', model_file,\n",
    "        '-d', test_file,\n",
    "        '-p', predictions_file,\n",
    "    ], predictions_file\n",
    "\n",
    "\n",
    "xgboost_conf = [\n",
    "    'booster = gbtree',\n",
    "    'objective = binary:logistic',\n",
    "    'nthread = 24',\n",
    "    'eval_metric = logloss',\n",
    "    'max_depth = 7',\n",
    "    'num_round = 200',\n",
    "    'eta = 0.2',\n",
    "    'gamma = 0.4',\n",
    "    'subsample = 0.8',\n",
    "    'colsample_bytree = 0.8',\n",
    "    'min_child_weight = 20',\n",
    "    'alpha = 3',\n",
    "    'lambda = 100',\n",
    "]\n",
    "\n",
    "\n",
    "def get_xgboost_commands_and_predictions_file(train_file, test_file, cache=False):\n",
    "    config_file = os.path.join(local_runtime_path, 'xgb.conf')\n",
    "    ensure_directory_exists(local_runtime_path)\n",
    "    with open(config_file, 'wb') as f:\n",
    "        for line in xgboost_conf:\n",
    "            print(line, file=f)\n",
    "    model_file = train_file + '.model'\n",
    "    predictions_file = test_file + '.predictions'\n",
    "    if cache:\n",
    "        train_file = train_file + '#' + train_file + '.cache'\n",
    "    return [\n",
    "        'xgboost',\n",
    "        config_file,\n",
    "        'data=' + train_file,\n",
    "        'model_out=' + model_file,\n",
    "    ], [\n",
    "        'xgboost',\n",
    "        config_file,\n",
    "        'task=pred',\n",
    "        'test:data=' + test_file,\n",
    "        'model_in=' + model_file,\n",
    "        'name_pred=' + predictions_file,\n",
    "    ], predictions_file\n",
    "\n",
    "def get_xgboost_ooc_commands_and_predictions_file(train_file, test_file):\n",
    "    return get_xgboost_commands_and_predictions_file(train_file, test_file, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 334 µs (started: 2022-11-16 12:55:59 +00:00)\n"
     ]
    }
   ],
   "source": [
    "engines = {\n",
    "    'vw': (get_vw_commands_and_predictions_file, local_vw_train_template, local_vw_test_template),\n",
    "    'xgb': (get_xgboost_commands_and_predictions_file, local_libsvm_train_template, local_libsvm_test_template),\n",
    "    'xgb.ooc': (get_xgboost_ooc_commands_and_predictions_file, local_libsvm_train_template, local_libsvm_test_template),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train & test everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.61 ms (started: 2022-11-16 12:55:59 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import vowpalwabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-16 12:55:59,556] Training \"vw\" on \"10000\" lines of data.\n",
      "[2022-11-16 12:55:59,557] Will train on \"criteo/data/data.train.10k.vw\" and test on \"criteo/data/data.test.1kk.vw\".\n",
      "time_file criteo/data/data.train.10k.vw.time\n",
      "command_engine_train:  ['vw83', '--link=logistic', '--loss_function=logistic', '-b', '29', '-l', '0.3', '--initial_t', '1', '--decay_learning_rate', '0.5', '--power_t', '0.5', '--l1', '1e-15', '--l2', '0', '-d', 'criteo/data/data.train.10k.vw', '-f', 'criteo/data/data.train.10k.vw.model']\n",
      "command_engine_test:  ['vw83', '--loss_function=logistic', '-t', '-i', 'criteo/data/data.train.10k.vw.model', '-d', 'criteo/data/data.test.1kk.vw', '-p', 'criteo/data/data.test.1kk.vw.predictions']\n",
      "predictions_file:  criteo/data/data.test.1kk.vw.predictions\n",
      "[2022-11-16 12:55:59,558] Performing train.\n",
      "[2022-11-16 12:55:59,570] Performing test.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/time: cannot run vw83: No such file or directory\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'vw83'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/dataset/fengwen/script/criteo-1tb-benchmark/notebooks/experiment_local.ipynb Cell 73\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Boneflow27-root/data/dataset/fengwen/script/criteo-1tb-benchmark/notebooks/experiment_local.ipynb#Y132sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m subprocess\u001b[39m.\u001b[39mcall(command_time \u001b[39m+\u001b[39m command_engine_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Boneflow27-root/data/dataset/fengwen/script/criteo-1tb-benchmark/notebooks/experiment_local.ipynb#Y132sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mPerforming test.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Boneflow27-root/data/dataset/fengwen/script/criteo-1tb-benchmark/notebooks/experiment_local.ipynb#Y132sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m subprocess\u001b[39m.\u001b[39;49mcall(command_engine_test)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Boneflow27-root/data/dataset/fengwen/script/criteo-1tb-benchmark/notebooks/experiment_local.ipynb#Y132sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mMeasuring results.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Boneflow27-root/data/dataset/fengwen/script/criteo-1tb-benchmark/notebooks/experiment_local.ipynb#Y132sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m measurement \u001b[39m=\u001b[39m measure(engine, sample, test_file, time_file, predictions_file)\n",
      "File \u001b[0;32m~/miniconda3/envs/spark/lib/python3.8/subprocess.py:340\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39m*\u001b[39mpopenargs, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    333\u001b[0m     \u001b[39m\"\"\"Run command with arguments.  Wait for command to complete or\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m    timeout, then return the returncode attribute.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[39m    retcode = call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m     \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m p:\n\u001b[1;32m    341\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m             \u001b[39mreturn\u001b[39;00m p\u001b[39m.\u001b[39mwait(timeout\u001b[39m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/spark/lib/python3.8/subprocess.py:858\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[1;32m    855\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    856\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 858\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    859\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    860\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    861\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    862\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    863\u001b[0m                         errread, errwrite,\n\u001b[1;32m    864\u001b[0m                         restore_signals, start_new_session)\n\u001b[1;32m    865\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    866\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    867\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m~/miniconda3/envs/spark/lib/python3.8/subprocess.py:1704\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1702\u001b[0m     \u001b[39mif\u001b[39;00m errno_num \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1703\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1704\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1705\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'vw83'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 718 ms (started: 2022-11-16 12:55:59 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "BREAD_OUT = False\n",
    "\n",
    "measurements = []\n",
    "\n",
    "for sample in train_samples:\n",
    "    for engine in engines:\n",
    "\n",
    "        logger.info('Training \"%s\" on \"%s\" lines of data.', engine, sample)\n",
    "        \n",
    "        get_commands_and_predictions_file, train_template, test_template = engines[engine]\n",
    "\n",
    "        train_file = train_template.format(sample_name(sample))\n",
    "        test_file = test_template.format(sample_name(test_samples[0]))\n",
    "        logger.info('Will train on \"%s\" and test on \"%s\".', train_file, test_file)\n",
    "\n",
    "        command_time, time_file = get_time_command_and_file(train_file)\n",
    "        command_engine_train, command_engine_test, predictions_file = get_commands_and_predictions_file(train_file, test_file)\n",
    "        \n",
    "        print(\"command_engine_train: \",command_engine_train)\n",
    "        print(\"command_engine_test: \",command_engine_test)\n",
    "        print(\"predictions_file: \",predictions_file)\n",
    "\n",
    "        logger.info('Performing train.')\n",
    "        subprocess.call(command_time + command_engine_train)\n",
    "\n",
    "        logger.info('Performing test.')\n",
    "        subprocess.call(command_engine_test)\n",
    "\n",
    "        logger.info('Measuring results.')\n",
    "        measurement = measure(engine, sample, test_file, time_file, predictions_file)\n",
    "        logger.info(measurement)\n",
    "        measurements.append(measurement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "\n",
    "measurements_df = pandas.DataFrame(measurements).sort_values(by=['Engine', 'Train size'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extract_data_for_plotting(df, what):\n",
    "    return reduce(\n",
    "        lambda left, right: pandas.merge(left, right, how='outer', on='Train size'),\n",
    "        map(\n",
    "            lambda name: df[df.Engine == name][['Train size', what]].rename(columns={what: name}),\n",
    "            df.Engine.unique(),\n",
    "        ),\n",
    "    )   \n",
    "\n",
    "def plot_stuff(df, what, ylabel=None, **kwargs):\n",
    "    data = extract_data_for_plotting(df, what).set_index('Train size')\n",
    "    ax = data.plot(marker='o', figsize=(6, 6), title=what, grid=True, linewidth=2.0, **kwargs)  # xlim=(1e4, 4e9)\n",
    "    if ylabel is not None:\n",
    "        ax.set_ylabel(ylabel)\n",
    "\n",
    "\n",
    "plot_stuff(measurements_df, 'ROC AUC', logx=True)\n",
    "plot_stuff(measurements_df, 'Log loss', logx=True)\n",
    "plot_stuff(measurements_df, 'Train time', loglog=True, ylabel='s')\n",
    "plot_stuff(measurements_df, 'Maximum memory', loglog=True, ylabel='bytes')\n",
    "plot_stuff(measurements_df, 'CPU load', logx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbd4619f67b9664c31edb746e4b525700afe74fa73c626af4ea922efcdc904cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
